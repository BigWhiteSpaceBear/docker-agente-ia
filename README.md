# README

<details open>
<summary></b>üìó Guia de Configura√ß√£o</b></summary>

- üê≥ [Docker Compose](#-docker-compose)
- üê¨ [Docker environment variables](#-docker-environment-variables)
- üêã [Service configuration](#-service-configuration)
- üìã [Setup Examples](#-setup-examples)

</details>

## Vis√£o Geral

Este guia fornece instru√ß√µes passo a passo para configurar o RAGFlow com integra√ß√£o do Ollama como provedor de LLM. O RAGFlow √© um motor de Recupera√ß√£o Aumentada por Gera√ß√£o (RAG) que permite criar bases de conhecimento e fazer perguntas sobre seus documentos usando intelig√™ncia artificial.

Pr√©-requisitos

- Docker e Docker Compose instalados
- M√≠nimo 16GB de RAM dispon√≠vel
- M√≠nimo 50GB de espa√ßo em disco
- Windows com WSL2 (ou Linux/macOS)

## Etapa 1: Iniciar os Servi√ßos Docker
**1.1 Navegar at√© a pasta do projeto**


**1.2 Iniciar todos os containers**
Execute o comando para iniciar todos os servi√ßos:
  `docker-compose up -d`

Sa√≠da esperada:
[+]: # "Running 8/8"
 ‚úî Container es01                 Running
 ‚úî Container mysql                Healthy
 ‚úî Container minio                Running
 ‚úî Container redis                Running
 ‚úî Container ollama               Running
 ‚úî Container ragflow              Running
 ‚úî Container crewai_app           Running

 1.3 Verificar o status dos containers

Para confirmar que todos os servi√ßos est√£o rodando corretamente:

docker-compose ps

Todos os containers devem aparecer com status Up ou Healthy.

1.4 Aguardar a inicializa√ß√£o completa

O RAGFlow pode levar de 3 a 5 minutos para inicializar completamente na primeira execu√ß√£o. Para acompanhar o progresso:

Bash

docker logs -f ragflow
docker logs -f ragflow

Aguarde at√© ver a mensagem:

Plain Text

 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:9380

Etapa 2: Instalar Modelos do Ollama

2.1 Instalar o modelo de chat (Llama 3.1 )

O Ollama √© um servidor de LLM local que fornece modelos de linguagem. Instale o modelo principal:

Bash

docker exec -it ollama ollama pull llama3.1

Este comando pode levar alguns minutos, dependendo da sua conex√£o de internet. O modelo tem aproximadamente 4.7GB.

Sa√≠da esperada:

Plain Text

pulling manifest
pulling 8934d3f265a7
pulling 5c40d7dd6c4f
...
success

2.2 Instalar o modelo de embedding

Para que o RAGFlow possa vetorizar seus documentos, instale um modelo de embedding:

Bash

docker exec -it ollama ollama pull nomic-embed-text

Ou, alternativamente:

Bash

docker exec -it ollama ollama pull mxbai-embed-large

Nota: O modelo de embedding √© menor (~300MB) e essencial para a busca sem√¢ntica.

2.3 Verificar modelos instalados

Para confirmar que os modelos foram instalados corretamente:

Bash

docker exec -it ollama ollama list

Sa√≠da esperada:

Plain Text

NAME                    ID              SIZE      MODIFIED
llama3.1:latest         365c0bd3c000    4.7GB     2 minutes ago
nomic-embed-text:latest 0d3e4823be78    274MB     1 minute ago

Etapa 3: Configurar o RAGFlow

3.1 Acessar a interface do RAGFlow

Abra seu navegador e acesse:

Plain Text

http://localhost

Voc√™ deve ver a tela inicial do RAGFlow.

3.2 Criar uma conta

1.Clique em Sign Up (ou Registrar )

2.Preencha os dados:

‚Ä¢Email: seu-email@exemplo.com

‚Ä¢Senha: escolha uma senha segura
‚Ä¢Confirmar Senha: repita a senha

3.Clique em Sign Up para criar a conta

4.Fa√ßa login com suas credenciais

3.3 Configurar o Ollama como provedor de LLM

3.3.1 Acessar as configura√ß√µes

1.Clique no √≠cone de engrenagem (‚öôÔ∏è) no canto superior direito

2.Selecione Model Providers ou Provedores de Modelo

3.3.2 Adicionar o modelo de Chat

1.Clique em Add Model Provider ou Adicionar Provedor

2.Selecione Ollama da lista

3.Preencha os campos:

Campo
Valor
Model type
chat
Model name
llama3.1
Base url
http://ollama:11434
API-Key
(deixe em branco )
Max tokens
4096

1.Clique em Save ou Salvar

3.3.3 Adicionar o modelo de Embedding

1. Clique novamente em Add Model Provider

2. Selecione Ollama

3. Preencha os campos:

Campo
Valor
Model type
embedding
Model name
nomic-embed-text
Base url
http://ollama:11434
API-Key
(deixe em branco )
Max tokens
512

1.Clique em Save ou Salvar

Resultado esperado: Ambos os modelos devem aparecer na lista de provedores com status ‚úì (verificado).

Etapa 4: Criar e Configurar um Dataset

4.1 Acessar a se√ß√£o de Knowledge Base

1.No menu lateral, clique em Knowledge Base ou Base de Conhecimento

2.Clique em Create Dataset ou Criar Dataset

4.2 Configurar o Dataset

1.Preencha os dados:

‚Ä¢Dataset Name: Nome descritivo (ex: "Pol√≠ticas de Cr√©dito")

‚Ä¢Description: Descri√ß√£o do conte√∫do (ex: "Documentos sobre pol√≠ticas de cr√©dito e regulamenta√ß√µes")

2.Configure as op√ß√µes:

‚Ä¢ Embedding Model: Selecione nomic-embed-text (ou o modelo que voc√™ instalou)

‚Ä¢ Chunk Size: 800 (tamanho dos peda√ßos de texto)

‚Ä¢ Overlap: 100 (sobreposi√ß√£o entre chunks)

3.Clique em Create ou Criar

4.3 Fazer upload de arquivos

4.3.1 Preparar os documentos

Prepare seus documentos em um dos formatos suportados:

‚Ä¢ PDF (.pdf)

‚Ä¢ Word (.docx, .doc)

‚Ä¢ Texto (.txt)

‚Ä¢ Markdown (.md)

‚Ä¢ Imagens (.png, .jpg, .jpeg)

Dica: Para melhores resultados, use documentos bem estruturados e sem muitas imagens.

4.3.2 Fazer upload

1.Acesse o dataset que voc√™ criou

2.Clique em Upload ou Fazer Upload

3.Selecione um ou mais arquivos do seu computador

4.Clique em Upload para enviar

Exemplo de arquivos √∫teis:

‚Ä¢
Pol√≠ticas de cr√©dito da institui√ß√£o

‚Ä¢
Regulamenta√ß√µes do Banco Central

‚Ä¢
Manuais de procedimentos

‚Ä¢
Documentos de compliance

4.4 Aguardar o processamento

O RAGFlow processar√° os documentos:

1.Extra√ß√£o de texto: Extrai o conte√∫do dos arquivos

2.Chunking: Divide o texto em peda√ßos menores

3.Embedding: Converte os chunks em vetores sem√¢nticos

4.Indexa√ß√£o: Armazena os vetores no Elasticsearch

Tempo estimado: 1-5 minutos por documento, dependendo do tamanho.

Voc√™ pode acompanhar o progresso na interface. Quando terminar, o status mudar√° para Completed ou Conclu√≠do.

4.5 Verificar o Dataset

1.Clique no dataset para abrir os detalhes

2.Voc√™ deve ver:

‚Ä¢N√∫mero de documentos processados

‚Ä¢N√∫mero de chunks criados

‚Ä¢Status de indexa√ß√£o

Etapa 5: Testar o Sistema

5.1 Fazer uma pergunta ao Dataset

1.No dataset, clique em Chat ou Conversa

2.Digite uma pergunta sobre o conte√∫do dos seus documentos

3.Exemplo: "Qual √© a taxa de juros padr√£o para cr√©dito pessoa f√≠sica?"

4.Pressione Enter ou clique em Send

O RAGFlow deve:

1.Buscar documentos relevantes

2.Enviar para o Ollama processar

3.Retornar uma resposta baseada nos documentos

5.2 Verificar a qualidade das respostas

‚Ä¢As respostas devem ser baseadas nos documentos
‚Ä¢Deve haver refer√™ncias aos documentos usados
‚Ä¢A resposta deve ser relevante e precisa

Etapa 6: Obter Credenciais para Integra√ß√£o

Se voc√™ deseja integrar o RAGFlow com o sistema de agentes (CrewAI), voc√™ precisar√°:

6.1 Obter a API Key

1.V√° em Settings > API Keys

2.Clique em Create API Key ou Criar Chave de API

3.D√™ um nome descritivo (ex: "CrewAI Integration")

4.Copie a chave gerada

5.Guarde em local seguro - voc√™ n√£o poder√° ver novamente

6.2 Obter o Dataset ID

1.V√° em Knowledge Base

2.Clique no dataset que voc√™ criou

3.O ID est√° na URL: http://localhost/knowledge/datasets/{DATASET_ID}

4.Copie o DATASET_ID

6.3 Atualizar o arquivo .env

Se estiver usando o sistema de agentes, atualize o arquivo .env:

Plain Text

RAGFLOW_API_KEY=sua-chave-aqui
RAGFLOW_DATASET_ID=seu-dataset-id-aqui

Solu√ß√£o de Problemas

Problema: P√°gina "Welcome to nginx"

Solu√ß√£o:

1.Aguarde mais alguns minutos (at√© 5 minutos na primeira execu√ß√£o )

2.Tente acessar http://localhost:9380 diretamente

3.Verifique os logs: docker logs ragflow

Problema: Ollama n√£o responde

Solu√ß√£o:

Bash

# Verifique se o container est√° rodando
docker ps | grep ollama

# Veja os logs
docker logs ollama

# Reinicie o container
docker restart ollama

Problema: Modelos n√£o aparecem na lista

Solu√ß√£o:

1.Verifique se os modelos foram instalados: docker exec -it ollama ollama list
2.Reinicie o RAGFlow: docker restart ragflow
3.Atualize a p√°gina do navegador (Ctrl+F5 )

Problema: Upload de arquivo falha

Solu√ß√£o:

1.Verifique o tamanho do arquivo (m√°ximo recomendado: 100MB)
2.Verifique se o formato √© suportado
3.Verifique os logs: docker logs ragflow
4.Tente fazer upload de um arquivo menor primeiro

Problema: Elasticsearch n√£o inicia

Solu√ß√£o:

Bash

# Aumentar o limite de mem√≥ria no WSL2
wsl -d docker-desktop -u root
sysctl -w vm.max_map_count=262144
exit

# Reiniciar os containers
docker-compose down
docker-compose up -d

Servi√ßos e Portas

Servi√ßo
URL
Descri√ß√£o
RAGFlow
http://localhost
Interface web principal
RAGFlow API
http://localhost:9380
API REST do RAGFlow
Ollama
http://localhost:11434
API do Ollama
MinIO
http://localhost:9001
Console de armazenamento
MySQL
localhost:3306
Banco de dados
Elasticsearch
localhost:9200
Motor de busca
Redis
localhost:6379
Cache

Pr√≥ximos Passos

Ap√≥s configurar o RAGFlow, voc√™ pode:

1.Criar m√∫ltiplos datasets para diferentes √°reas de conhecimento

2.Integrar com o sistema de agentes (CrewAI ) para an√°lises autom√°ticas

3.Configurar webhooks para automa√ß√µes

4.Usar a API REST para integra√ß√£o com outras aplica√ß√µes

5.Fazer backup dos datasets regularmente

Refer√™ncias

‚Ä¢ RAGFlow Documenta√ß√£o: https://github.com/infiniflow/ragflow
‚Ä¢ Ollama Documenta√ß√£o: https://ollama.ai
‚Ä¢ Docker Compose: https://docs.docker.com/compose/
